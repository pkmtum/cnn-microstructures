{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Notebook for training several Autoencoders with different configurations**"
      ],
      "metadata": {
        "id": "HuywIGuPavZS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set Up"
      ],
      "metadata": {
        "id": "nDkBtjUvatj6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the path to the helper functions folder\n",
        "# On drive for example: '/content/drive/My Drive/myfolder/helper_functions'\n",
        "modules_path = './helper_functions'\n",
        "models_path = './models' # for the models folder\n",
        "\n",
        "# This is the path to the data folder\n",
        "# On drive for example: '/content/drive/myfolder/data'\n",
        "base_path = './data/'\n",
        "\n",
        "# This is the path to the tensorflow checkpoint folder\n",
        "# On drive for example: '/content/drive/MyDrive/best_models'\n",
        "checkpoint_filepath = './best_models'"
      ],
      "metadata": {
        "id": "vlzH9syEas6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NcxETSaMsUcQ"
      },
      "outputs": [],
      "source": [
        "# pip calls\n",
        "!pip install tensorflow_addons\n",
        "\n",
        "# all the nice imports <3\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import keras\n",
        "import importlib\n",
        "import pickle\n",
        "\n",
        "# black magic, so that tf.Tensor objects can be used as numpy things\n",
        "# all hail tensorflow 0_0\n",
        "from tensorflow.python.ops.numpy_ops import np_config\n",
        "np_config.enable_numpy_behavior()\n",
        "\n",
        "# show important library versions\n",
        "print(\"TensorFlow version: {}\".format(tf.__version__))\n",
        "print(\"TensorFlow Datasets version: \",tfds.__version__)\n",
        "\n",
        "\n",
        "# add custom paths (to import the nice models and helper classes)\n",
        "import sys\n",
        "sys.path.append(models_path)\n",
        "sys.path.append(modules_path)\n",
        "\n",
        "# add custom imports here\n",
        "import processing\n",
        "import metrics\n",
        "import autoencoder_models as am"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Very specific Colab things"
      ],
      "metadata": {
        "id": "CBQgnp-FbMRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import & mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# hardware speed-up magic (TPU OR GPU?)\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print('Warning: GPU device not found')\n",
        "else:  \n",
        "  print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "# Tensorboard stuff (callbacks for logging data)\n",
        "%load_ext tensorboard\n",
        "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)"
      ],
      "metadata": {
        "id": "iKpZ6nvFbL6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compile different contrast ratio data sets into one"
      ],
      "metadata": {
        "id": "5VGPpv-vvstt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# COMPLIE DIFFERENT DS INTO ONE\n",
        "# n=16_x=10000_cr=0.0020_DS.h5\n",
        "dataset_size = '1000'\n",
        "size = '64' # or 32 or 64\n",
        "\n",
        "cr = np.array(['0.1000', '0.0500', '0.0200', '0.0100', '0.0050', '0.0020'])\n",
        "\n",
        "size_path = size + 'x' + size + '/'\n",
        "paths = []\n",
        "tp_paths = []\n",
        "\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "for i in range(0, cr.shape[0]):\n",
        "  paths.append(base_path + size_path + 'n=' + size + '_x=' + dataset_size + '_cr=' + cr[i] + '_DS.h5')\n",
        "  tp_paths.append(base_path + size_path + 'n=' + size + '_x=' + dataset_size + '_cr=' + cr[i] + '_TP.h5')\n",
        "\n",
        "  f = h5py.File(paths[i], 'r')\n",
        "  tp_f = h5py.File(tp_paths[i], 'r')\n",
        "\n",
        "  imgs = np.array(f['images'])\n",
        "  labs = np.array(f['c_vectors'])\n",
        "  tp_imgs = np.array(tp_f['twopoint'])\n",
        "\n",
        "  f.close()\n",
        "\n",
        "  if len(images) == 0:\n",
        "    images = imgs\n",
        "    labels = labs\n",
        "    tp_images = tp_imgs\n",
        "  else:\n",
        "    images = np.append(images, imgs, axis=0)\n",
        "    labels = np.append(labels, labs, axis=0)\n",
        "\n",
        "    tp_images = np.append(tp_images, tp_imgs, axis=0)\n",
        "\n",
        "  \n",
        "\n",
        "print(\"Created image array of shape: \", images.shape)\n",
        "print(\"Created label array of shape: \", labels.shape)\n",
        "print(\"Created TP image array of shape: \", tp_images.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cYw0dqvvFX_",
        "outputId": "a64e6d16-aac0-4e60-c276-8e21b58a2947"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created image array of shape:  (6000, 4096)\n",
            "Created label array of shape:  (6000, 9)\n",
            "Created TP image array of shape:  (6000, 4096)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Old set up code\n",
        "Compile or get two-point correlation images, by computing 2-point correlations"
      ],
      "metadata": {
        "id": "pe-Rubrdv137"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RECOMPUTE_TP = False\n",
        "if RECOMPUTE_TP:\n",
        "\n",
        "  importlib.reload(processing)\n",
        "  dataproc = processing.Processing(\n",
        "      images, \n",
        "      labels, \n",
        "      np.array([0.8, 0.1, 0.1]), \n",
        "      batch_size=256, \n",
        "      conv_behavior=True, \n",
        "      scale_labels=False, \n",
        "      symmetric=True, \n",
        "      twopoint=True,\n",
        "      shuffle=False,\n",
        "      pca=False,\n",
        "      # pca_variance=0.7\n",
        "      )\n",
        "\n",
        "  tp_images = dataproc.images\n",
        "\n",
        "  f = h5py.File(base_path+size_path+'imgs_twopoint_'+size+'.h5', 'w')\n",
        "  f.create_dataset('twopoint', data=tp_images)\n",
        "  f.close()\n",
        "\n",
        "else:\n",
        "  f = h5py.File(base_path+size_path+'imgs_twopoint_'+size+'.h5', 'r')\n",
        "  tp_images = np.array(f['twopoint'])"
      ],
      "metadata": {
        "id": "5fOurZQi9JNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set Up of Code\n",
        "1. Size of test set\n",
        "1. problem and problem folder\n",
        "1. size of images"
      ],
      "metadata": {
        "id": "8cmdez3txC7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.\n",
        "TEST_SIZE = 1000\n",
        "EPOCHS = 1000\n",
        "\n",
        "# 2.\n",
        "PROBLEM = 'AUTO64'\n",
        "PROBLEM_FOLDER = 'autoencoders'\n",
        "\n",
        "# 3.\n",
        "sample_size = 64\n",
        "\n",
        "\n",
        "size = str(sample_size)\n",
        "size_path = size + 'x' + size + '/'\n",
        "model_base_path = './'+ PROBLEM_FOLDER + '/' + size_path"
      ],
      "metadata": {
        "id": "4Kvsj1AqKnbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Execution of Code"
      ],
      "metadata": {
        "id": "MkHd-eY5xfNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_array = []\n",
        "FILENAME = 'all_data_' + PROBLEM\n",
        "SPLITS = np.array([0.9, 0.1, 0])\n",
        "\n",
        "counter = 0\n",
        "\n",
        "ds_size_array = [5000]\n",
        "twopoint_array = [False]\n",
        "\n",
        "\n",
        "for ds in ds_size_array:\n",
        "  for tp in twopoint_array:\n",
        "\n",
        "    counter += 1\n",
        "    print(\"Currently working on model No.\", counter)\n",
        "\n",
        "    imgs = images\n",
        "    labs = labels\n",
        "    if tp:\n",
        "      imgs = tp_images\n",
        "    \n",
        "    print(imgs.shape)\n",
        "\n",
        "    dataproc = processing.Processing(\n",
        "      imgs[:ds], \n",
        "      labs[:ds], \n",
        "      SPLITS, \n",
        "      custom_test = (imgs[-TEST_SIZE:], labs[-TEST_SIZE:]),\n",
        "      batch_size=256, \n",
        "      conv_behavior=True, \n",
        "      scale_labels=False, \n",
        "      symmetric=True, \n",
        "      twopoint=False,\n",
        "      shuffle=False,\n",
        "      pca=False,\n",
        "      # pca_variance=0.7\n",
        "      )\n",
        "    print(dataproc.splits[0])\n",
        "    \n",
        "    encoder = am.create_enc_spec(inputshape=(sample_size,sample_size,1))\n",
        "    decoder = am.create_dec_spec(inputshape=(8,8,4))\n",
        "    autoencoder = am.ConvAuto(encoder, decoder)\n",
        "    print(autoencoder.summary())\n",
        "\n",
        "    \n",
        "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath=checkpoint_filepath,\n",
        "        save_weights_only=True,\n",
        "        monitor='val_r_square',\n",
        "        mode='max',\n",
        "        save_best_only=True)\n",
        "\n",
        "\n",
        "    train_data, val_data, test_data = dataproc.datasets_auto\n",
        "\n",
        "    params = {\n",
        "        'x' : train_data,\n",
        "        'batch_size' : dataproc.batch_size, \n",
        "        'epochs' : EPOCHS, \n",
        "        'validation_data' : val_data,\n",
        "        'verbose' : 1, \n",
        "        'callbacks' : [tensorboard_callback, model_checkpoint_callback]\n",
        "    }\n",
        "\n",
        "    autoencoder.compile(optimizer=\"Adam\", loss=\"mse\", metrics=tfa.metrics.RSquare())\n",
        "    history = autoencoder.fit(**params)\n",
        "\n",
        "    autoencoder.load_weights(checkpoint_filepath)\n",
        "\n",
        "    test_metrics = autoencoder.evaluate(test_data)\n",
        "\n",
        "    custom_path = PROBLEM + '_ds' + str(dataproc.splits[0]) + '_tp' + str(tp) + '_epochs' + str(params['epochs'])\n",
        "    total_path = model_base_path + custom_path\n",
        "    encoder.save(total_path)\n",
        "\n",
        "\n",
        "    results_array.append(\n",
        "        {\n",
        "            'run_name' : custom_path,\n",
        "            'model_name' : 'autoencoder',\n",
        "            'regularization' : 0,\n",
        "            'ds_size' : dataproc.splits[0],\n",
        "            'twopoint' : tp,\n",
        "            'contrast_ratio' : cr,\n",
        "            'epochs' : params['epochs'],\n",
        "            'history' : history.history,\n",
        "            'test_metrics' : test_metrics,\n",
        "            'model_function' : am.ConvAuto,\n",
        "            'path_to_weights' : total_path,\n",
        "        }\n",
        "    )\n",
        "\n",
        "\n",
        "with open(model_base_path + 'history/' + FILENAME, 'wb') as file_pi:\n",
        "  pickle.dump(results_array, file_pi)"
      ],
      "metadata": {
        "id": "qTQHFlh0I0zv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir logs/scalars"
      ],
      "metadata": {
        "id": "HlUIrcfyGA3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example of reconstruction evaluation"
      ],
      "metadata": {
        "id": "iFl7f_v3x-C1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index = 0\n",
        "original = imgs[index].reshape(1,32,32,1)\n",
        "\n",
        "pred = autoencoder(original)\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(np.squeeze(original))\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(np.squeeze(pred))\n",
        "plt.axis('off')\n",
        "\n",
        "plt.savefig('./autoencoder32_pred2pc'+str(index), pad_inches=0, dpi=200)"
      ],
      "metadata": {
        "id": "dSXVpLZrHXuu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "3897780a-83d9-4913-aa55-a2ee578fe32d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 32, 32, 1)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}