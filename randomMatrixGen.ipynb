{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Notebook to generate two-phase linear-elastic Microstructures**\n",
        "\n",
        "----------\n",
        "\n",
        "The Notebook is designed to be run on Google Colab. Except for the FEniCS import, it can run locally.\n",
        "\n",
        "Various parameters of the data sets to be created can be changed below\n",
        "\n",
        "NECESSARY: Give a specific path to modules\n",
        "\n",
        "----------\n",
        "\n",
        "Credit: \n",
        "\n",
        "Thanks for Tim Duka for writing the code this notebook is based on. It has been somewhat adapted and optimized.\n",
        "\n",
        "----------"
      ],
      "metadata": {
        "id": "35go-Zac3lfY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up"
      ],
      "metadata": {
        "id": "jOJXoxnI6UYl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qK9SSd8nHgKv"
      },
      "outputs": [],
      "source": [
        "# SET UP\n",
        "# Insert here the path to the modules in the folder \"helper_functions\"\n",
        "# Example: '/content/drive/myfolder/helper_functions'\n",
        "PATH_TO_MODULES = './helper_functions'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8n4N5Xqtc5lQ"
      },
      "outputs": [],
      "source": [
        "# Installation of FEniCS and Dolfin on Google Colab. Simplest way.\n",
        "# See: https://fem-on-colab.github.io/\n",
        "!wget \"https://fem-on-colab.github.io/releases/fenics-install.sh\" -O \"/tmp/fenics-install.sh\" && bash \"/tmp/fenics-install.sh\"\n",
        "\n",
        "from fenics import *\n",
        "import fenics\n",
        "from ufl import nabla_div\n",
        "from ufl import nabla_grad\n",
        "import numpy as np\n",
        "import numpy.linalg\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "\n",
        "import scipy\n",
        "from scipy.stats import norm\n",
        "from scipy.linalg import cholesky\n",
        "import time\n",
        "\n",
        "import h5py\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import sys\n",
        "# sys.path.append('/content/drive/MyDrive/Bachelor Thesis/models')\n",
        "sys.path.append(PATH_TO_MODULES)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function Definitions"
      ],
      "metadata": {
        "id": "jjTtAHjK6QUR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdiMpLRowhf0"
      },
      "outputs": [],
      "source": [
        "# Functions for sample generation\n",
        "\n",
        "def getMeshgrid(n, x_end=1, y_end=1):\n",
        "    \"\"\"Gives Back a nxn regular Meshgrid for the midpoints of the nxn cells in the defined area of the I quadrant\"\"\"\n",
        "    dx = x_end/n\n",
        "    x = np.linspace(dx/2, x_end-dx/2, n)\n",
        "    y = np.linspace(dx/2, y_end-dx/2, n)\n",
        "    \n",
        "    mesh = np.meshgrid(x, y)\n",
        "    return mesh\n",
        "\n",
        "    \n",
        "def getDistances(xx, yy):\n",
        "    x_cords = xx.flatten()  # 1D array of x_cords for all nodes\n",
        "    y_cords = yy.flatten()  # 1D array of y_cords for all nodes\n",
        "    # Now create square matrices (i,j) holding the x/y distance of nodes i & j\n",
        "    xx_cords = np.tile(x_cords, (len(x_cords), 1))\n",
        "    yy_cords = np.tile(y_cords, (len(y_cords), 1))\n",
        "    xx_distances = np.abs(xx_cords - xx_cords.T)\n",
        "    yy_distances = np.abs(yy_cords - yy_cords.T)\n",
        "\n",
        "    return xx_distances, yy_distances\n",
        "\n",
        "\n",
        "def nearestPD(A):\n",
        "    \"\"\"Find the nearest positive-definite matrix to input\n",
        "\n",
        "    A Python/Numpy port of John D'Errico's `nearestSPD` MATLAB code [1], which\n",
        "    credits [2].\n",
        "\n",
        "    [1] https://www.mathworks.com/matlabcentral/fileexchange/42885-nearestspd\n",
        "\n",
        "    [2] N.J. Higham, \"Computing a nearest symmetric positive semidefinite\n",
        "    matrix\" (1988): https://doi.org/10.1016/0024-3795(88)90223-6\n",
        "    \"\"\"\n",
        "\n",
        "    B = (A + A.T) / 2\n",
        "    _, s, V = np.linalg.svd(B)\n",
        "\n",
        "    H = np.dot(V.T, np.dot(np.diag(s), V))\n",
        "\n",
        "    A2 = (B + H) / 2\n",
        "\n",
        "    A3 = (A2 + A2.T) / 2\n",
        "\n",
        "    if isPD(A3):\n",
        "        return A3\n",
        "\n",
        "    spacing = np.spacing(np.linalg.norm(A))\n",
        "    # The above is different from [1]. It appears that MATLAB's `chol` Cholesky\n",
        "    # decomposition will accept matrixes with exactly 0-eigenvalue, whereas\n",
        "    # Numpy's will not. So where [1] uses `eps(mineig)` (where `eps` is Matlab\n",
        "    # for `np.spacing`), we use the above definition. CAVEAT: our `spacing`\n",
        "    # will be much larger than [1]'s `eps(mineig)`, since `mineig` is usually on\n",
        "    # the order of 1e-16, and `eps(1e-16)` is on the order of 1e-34, whereas\n",
        "    # `spacing` will, for Gaussian random matrixes of small dimension, be on\n",
        "    # othe order of 1e-16. In practice, both ways converge, as the unit test\n",
        "    # below suggests.\n",
        "    I = np.eye(A.shape[0])\n",
        "    k = 1\n",
        "    while not isPD(A3):\n",
        "        mineig = np.min(np.real(np.linalg.eigvals(A3)))\n",
        "        A3 += I * (-mineig * k**2 + spacing)\n",
        "        k += 1\n",
        "\n",
        "    return A3\n",
        "\n",
        "\n",
        "def isPD(B):\n",
        "    \"\"\"Returns true when input is positive-definite, via Cholesky\"\"\"\n",
        "    try:\n",
        "        _ = np.linalg.cholesky(B)\n",
        "        return True\n",
        "    except np.linalg.LinAlgError:\n",
        "        return False\n",
        "\n",
        "\n",
        "def createCovarianceMatrix(xx_distances, yy_distances, A_e, ar, sigma, rel_corr):\n",
        "    \"\"\"\n",
        "    Creates the Covariance Matrix for use in a multivariate Gaussian RNG to\n",
        "    create Images of blobs of 2 different phases on a 2D rectangle\n",
        "    \"\"\"\n",
        "    lx = np.pi / (A_e * ar)\n",
        "    ly = (np.pi * ar) / A_e\n",
        "    d = np.log(1 / rel_corr)\n",
        "    cov = (sigma ** 2) * np.exp(-d * (lx * xx_distances ** 2 + ly * yy_distances ** 2))\n",
        "\n",
        "    eps = 1e-13\n",
        "    offset = np.diag(np.repeat(eps,cov.shape[0]))\n",
        "\n",
        "    # cov = cov * (1 - eps) + offset\n",
        "    cov = cov + offset\n",
        "\n",
        "    return cov\n",
        "\n",
        "\n",
        "def createRandomValuesForImage(mean, cov):\n",
        "    # approach 1: good but slow\n",
        "    # ran = np.random.multivariate_normal(mean, cov)\n",
        "    # approach 3\n",
        "    ran = mean + np.linalg.cholesky(cov) @ np.random.standard_normal(mean.size)\n",
        "\n",
        "    return ran\n",
        "\n",
        "\n",
        "def generateImageArray(ran, n, cutoff):\n",
        "    img = np.zeros(len(ran))\n",
        "    img[ran > cutoff] = 1\n",
        "    return img\n",
        "\n",
        "\n",
        "def generate_image(n=10, sigma=1, A_ellipse=0.25, a_r=1, rel_cor=0.01, vol_frac=0.5):\n",
        "    # Global Parameters:\n",
        "    n = n\n",
        "    sigma = sigma\n",
        "    A_ellipse = A_ellipse  # Area of the ellipse\n",
        "    ar = a_r  # AxisRatio of the ellipse's axes rx/ry\n",
        "    rel_cor = rel_cor  # relative value of correlation along ellipse boundary\n",
        "    vol_frac = vol_frac  # fraction of the volume that will be filled with phase 1 in a mean sense\n",
        "    z_cutoff = 0  # cutoff value fixed\n",
        "    mu = z_cutoff - sigma * norm.ppf(vol_frac)  # mean to achieve vol_frac of phase 1\n",
        "\n",
        "    xx, yy = getMeshgrid(n)\n",
        "\n",
        "    # start = time.process_time()\n",
        "    xx_dist, yy_dist = getDistances(xx, yy)\n",
        "    # print('Time for distances: ', time.process_time() - start)\n",
        "\n",
        "    start = time.process_time()\n",
        "    cov = createCovarianceMatrix(xx_dist, yy_dist, A_ellipse, ar, sigma, rel_cor)\n",
        "    # print('Time for cov matrix: ', time.process_time() - start)\n",
        "\n",
        "    mean = mu * np.ones(n ** 2)\n",
        "\n",
        "    start = time.process_time()\n",
        "    ran = createRandomValuesForImage(mean, cov)\n",
        "    # print('Time for drawing from MVG: ', time.process_time() - start)\n",
        "\n",
        "    # start = time.process_time()\n",
        "    img = generateImageArray(ran, n, z_cutoff)\n",
        "    # print('Time for image generation: ', time.process_time() - start)\n",
        "\n",
        "    return ran, img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HhJpVeXSHc95"
      },
      "outputs": [],
      "source": [
        "# calculating the material matrix\n",
        "\n",
        "def calculate_material_matrix(rand_vec, n=10, E_1=1., contrast_ratio=0.5, nu=0.3):\n",
        "    # Variables\n",
        "    rand_vec = rand_vec\n",
        "    n = n\n",
        "    E_1 = E_1  # E-Modul\n",
        "    nu = nu  # Poisson's number\n",
        "    frac = 1 / contrast_ratio\n",
        "    E_2 = frac * E_1\n",
        "    eps_bar = np.array([[1, 0, 0],\n",
        "                        [0, 1, 0],\n",
        "                        [0, 0, 1]])  # according to Miehe, 2002: eps_bar[:,x] = [ \\eps_11, \\eps_22, 2*\\eps_12]\n",
        "\n",
        "    # Create mesh and define function space\n",
        "    mesh = UnitSquareMesh(n, n)\n",
        "    # mesh = RectangleMesh(Point(0., 0.), Point(1., 100.), 3, 20)\n",
        "    V = VectorFunctionSpace(mesh, 'P', 1)\n",
        "\n",
        "    # Define boundary condition\n",
        "\n",
        "    def boundary(x, on_boundary):\n",
        "        return on_boundary\n",
        "\n",
        "    # Define mesh function for material boundaries\n",
        "    tol = 1E-12\n",
        "    materials = MeshFunction('size_t', mesh, mesh.topology().dim(), 0)\n",
        "    domain = rand_vec.reshape(n, n)\n",
        "    materials_domain = np.zeros((n, 2 * n)).astype(int)  # since mesh is triangular one need double the entries\n",
        "    for i in range(n):  # due to fenics mesh function,\n",
        "        materials_domain[n - i - 1, ::2] = domain[i, :]\n",
        "        materials_domain[n - i - 1, 1::2] = domain[i, :]\n",
        "    materials.array()[:] = materials_domain.flatten()\n",
        "    File('materials2D.xml') << materials\n",
        "\n",
        "    class E(UserExpression):\n",
        "        def __init__(self, material, e_1, e_2, *args, **kwargs):\n",
        "            super().__init__(*args, **kwargs)\n",
        "            self.material = material\n",
        "            self.e_1 = e_1\n",
        "            self.e_2 = e_2\n",
        "\n",
        "        def eval_cell(self, values, x, cell):\n",
        "            if self.material[cell.index] == 0:\n",
        "                values[0] = self.e_1\n",
        "            else:\n",
        "                values[0] = self.e_2\n",
        "\n",
        "        def value_shape(self):\n",
        "            # return (1,)\n",
        "            return ()\n",
        "\n",
        "    # Define strain and stress\n",
        "    e_mod = E(materials, E_1, E_2)\n",
        "\n",
        "    def lambda_(E, nu):\n",
        "        return (E * nu) / ((1 + nu) * (1 - 2 * nu))  # Lame's 1st parameter\n",
        "\n",
        "    def mu(E, nu):\n",
        "        return E / (2 * (1 + nu))  # Lame's 2nd parameter\n",
        "\n",
        "    def epsilon(u):\n",
        "        return 0.5 * (nabla_grad(u) + nabla_grad(u).T)\n",
        "        # return sym(nabla_grad(u))\n",
        "\n",
        "    def lambda_prime(lambd, mue):\n",
        "        return 2 * lambd * mue / (lambd + 2 * mue)\n",
        "\n",
        "    # according to https://comet-fenics.readthedocs.io/en/latest/demo/elasticity/2D_elasticity.py.html\n",
        "\n",
        "    def sigma(u):\n",
        "        return lambda_prime(lambda_(e_mod, nu), mu(e_mod, nu)) * nabla_div(u) * Identity(2) + 2 * mu(e_mod,\n",
        "                                                                                                     nu) * epsilon(u)\n",
        "    # Define variational problem\n",
        "    u = TrialFunction(V)\n",
        "    d = u.geometric_dimension()  # space dimension\n",
        "    v = TestFunction(V)\n",
        "    f = Constant((0, 0))\n",
        "    a = fenics.inner(sigma(u), epsilon(v)) * dx\n",
        "    L = dot(f, v) * dx\n",
        "\n",
        "    # Assemble System Matrix\n",
        "    A = assemble(a)\n",
        "    K = A.array()\n",
        "\n",
        "    # print(\"here 1\")\n",
        "\n",
        "    # dof's:\n",
        "    geometrical_dim = mesh.geometry().dim()\n",
        "    dof_cords = V.tabulate_dof_coordinates()  # Coordinates of all dofs in system\n",
        "    vertex_cords = dof_cords[1::2, :]\n",
        "\n",
        "    # construct boolean index vectors for boundary and inner nodes\n",
        "    boundary_left = dof_cords[:, 0] < tol\n",
        "    boundary_right = dof_cords[:, 0] > 1 - tol\n",
        "    boundary_top = dof_cords[:, 1] > 1 - tol\n",
        "    boundary_bottom = dof_cords[:, 1] < tol\n",
        "    bound = boundary_left + boundary_right + boundary_top + boundary_bottom\n",
        "    inner = ~bound\n",
        "    \n",
        "\n",
        "    # del boundary_left, boundary_right, boundary_bottom, boundary_top\n",
        "    # del A, u, d, v, f, a, L\n",
        "\n",
        "    # print(\"here 2\")\n",
        "    # Construct submatrices: a = inner nodes, b = boundary nodes\n",
        "    #  ___________   ___     ___\n",
        "    # | K_aa K_ab | |u_a| _ |f_a|\n",
        "    # | K_ba K_bb | |u_b| ‾ |f_b|\n",
        "    #  ‾‾‾‾‾‾‾‾‾‾‾   ‾‾‾     ‾‾‾\n",
        "\n",
        "    K_aa = K[inner, :][:, inner]\n",
        "    # print(\"K_aa done\")\n",
        "    K_ab = K[inner, :][:, bound]\n",
        "    # print(\"K_ab done\")\n",
        "    K_ba = K[bound, :][:, inner]\n",
        "    # print(\"K_ba done\")\n",
        "    K_bb = K[bound, :][:, bound]\n",
        "    # print(\"K_bb done\")\n",
        "\n",
        "    \n",
        "    \n",
        "    # del K, vertex_cords\n",
        "\n",
        "    # print(\"here 3\")\n",
        "    # Construct D matrix according to Miehe, 2002\n",
        "    #  __________________\n",
        "    # |   x_1       0    |\n",
        "    # |    0       x_2   | = D_q --> D = [ D_1 D_2 ... D_M ]\n",
        "    # | 0.5*x_2  0.5*x_1 |\n",
        "    #  ‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾\n",
        "    start = time.process_time()\n",
        "\n",
        "    bound_vertex_cords = dof_cords[bound, :][0::2, :]  # Coordinates of all vertices in system, gdim dofs per vertex\n",
        "    D = np.zeros((3, bound_vertex_cords.size))\n",
        "    D[0, 0::2] = bound_vertex_cords[:, 0]\n",
        "    D[1, 1::2] = bound_vertex_cords[:, 1]\n",
        "    D[2, 0::2] = 0.5 * bound_vertex_cords[:, 1]\n",
        "    D[2, 1::2] = 0.5 * bound_vertex_cords[:, 0]\n",
        "\n",
        "    # del bound_vertex_cords\n",
        "\n",
        "    \n",
        "\n",
        "    # print(\"Set up: \", time.process_time() - start)\n",
        "    start = time.process_time()\n",
        "    # Calculate Displacement on boundary according to Miehe , 2002\n",
        "    u_bound = D.T @ eps_bar\n",
        "\n",
        "\n",
        "    # Solve for inner node displacement\n",
        "    # K_aa is sparse so scipy.sparse is used\n",
        "    u_a = scipy.sparse.linalg.spsolve(scipy.sparse.csc_matrix(K_aa), -K_ab @ u_bound)\n",
        "    \n",
        "\n",
        "    # Construct dof displacement vector\n",
        "    u_vec = np.zeros((dof_cords.shape[0], eps_bar.shape[1]))\n",
        "    u_vec[inner, :] = u_a\n",
        "    u_vec[bound, :] = u_bound\n",
        "\n",
        "    # del u_vec\n",
        "\n",
        "\n",
        "    # print(\"First matrix mults: \", time.process_time() - start)\n",
        "    start = time.process_time()\n",
        "\n",
        "    # Calculate Nodal Forces\n",
        "    f_b = K_ba @ u_a + K_bb @ u_bound\n",
        "    # f_b_vec = f_b.reshape(-1, 2 * eps_bar.shape[1])\n",
        "    # del u_bound\n",
        "    # Calculate macroscopic stress vector according to Miehe, 2002\n",
        "    sigma_bar = D @ f_b\n",
        "\n",
        "    # Calculate tangent moduli according to Miehe, 2002\n",
        "    \"\"\"\n",
        "    # commented out for optim\n",
        "    K_bb_tilde = K_bb - K_ba @ np.linalg.inv(K_aa) @ K_ab\n",
        "    C = D @ K_bb_tilde @ D.T\n",
        "    \"\"\"\n",
        "\n",
        "    # Print infos for validation\n",
        "    # print('Nodal Coordinates:\\n', vertex_cords)\n",
        "    # print('Nodal Force Vector:\\n', f_b)\n",
        "    # print('Sigma bar:\\n', sigma_bar)\n",
        "    # print('Tangent moduli:\\n', C)\n",
        "    # print(\"Second matmuls: \", time.process_time() - start)\n",
        "\n",
        "    \"\"\"\n",
        "    for name, size in sorted(((name, sys.getsizeof(value)) for name, value in locals().items()),\n",
        "                          key= lambda x: -x[1])[:10]:\n",
        "      print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))\n",
        "    \"\"\"\n",
        "\n",
        "    \"\"\"\n",
        "    # Poisson ratio and E-mod:\n",
        "    poisson = [sigma_bar[1, 0] / sigma_bar[0, 0], sigma_bar[0, 1] / sigma_bar[1, 1]]\n",
        "    E_mod = [sigma_bar[0, 0] * (1 - poisson[0] ** 2), sigma_bar[1, 1] * (1 - poisson[1] ** 2)]\n",
        "    if __name__ == '__main__':\n",
        "        print('E-mod: ', E_mod, ', Sigma bar: ', sigma_bar)\n",
        "    \"\"\"\n",
        "    \n",
        "    return sigma_bar\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    vec = np.zeros(100)\n",
        "    vec[np.random.randint(0, 100, 5)] = 1\n",
        "    cMatrix = calculate_material_matrix(vec, n=10, E_1=1., contrast_ratio=0.1)\n",
        "    print('C matrix = ')\n",
        "    print(cMatrix)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Script to Create Data Set\n",
        "\n",
        "**Parameters:**\n",
        "\n",
        "```\n",
        "x: data set size\n",
        "n: side length of one sample\n",
        "a_r: array containing possible aspect ratios\n",
        "contrast_ratio: E_1/E_2\n",
        "binary: True: save as binary representation, False: Save gaussian distribution\n",
        "\n",
        "single_volume_frac, single_a_r: if true only the correpsonding value will be considered\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "13oN50xN48Xl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ESrdRKUuUQp"
      },
      "outputs": [],
      "source": [
        "# generating dataset\n",
        "\n",
        "x = 1000  # number of data points to be generated\n",
        "n = 32  # number of mesh elements per coordinate axis\n",
        "a_r = np.array([1/4, 1/3, 1/2, 1, 2, 3, 4])  # possible values for aspect ratio\n",
        "contrast_ratio = 0.002 # E_1 / E_2, currently 500\n",
        "\n",
        "binary = True\n",
        "\n",
        "conv_dataset = False\n",
        "\n",
        "single_volume_frac = False\n",
        "vol_frac_value = 0.25\n",
        "\n",
        "single_a_r = False\n",
        "a_r_value = 4\n",
        "\n",
        "images = np.zeros((x, n**2))  # stores all random sample vectors generated\n",
        "c_vectors = np.zeros((x, 9))  # stores all sample effective property c matrices (vectorized)\n",
        "areas_ellipse = np.zeros(x)\n",
        "aspect_ratios = np.zeros(x)\n",
        "volume_fractions = np.zeros(x)\n",
        "\n",
        "\n",
        "\n",
        "start = time.process_time()\n",
        "for i in range(x):\n",
        "    \n",
        "    if (i + 1) % max(int(x / 20),1) == 0:\n",
        "        print('%3.1f percent done' % (((i + 1) / x) * 100))\n",
        "    \n",
        "    if single_volume_frac:\n",
        "        volume_fractions[i] = vol_frac_value\n",
        "    else:\n",
        "        volume_fractions[i] = np.random.uniform(0.25, 0.75)\n",
        "\n",
        "    if single_a_r:\n",
        "        aspect_ratios[i] = a_r_value\n",
        "    else:\n",
        "        aspect_ratios[i] = a_r[np.random.randint(0, a_r.shape[0])]\n",
        "\n",
        "    areas_ellipse[i] = np.random.uniform(0.1, 0.9)\n",
        "    start_img_gen = time.process_time()\n",
        "    random, img = generate_image(n=n, sigma=1, A_ellipse=areas_ellipse[i], a_r=aspect_ratios[i], rel_cor=0.01,\n",
        "                                          vol_frac=volume_fractions[i])\n",
        "    \n",
        "    # random = images[i,:]\n",
        "    \n",
        "    # print(\"Image generation: \", time.process_time() - start_img_gen)\n",
        "\n",
        "    if binary:\n",
        "        images[i, :] = img\n",
        "  \n",
        "    # always pass binary data to FEM, but register correlation or binary in database\n",
        "    # pass img for binary calculation, pass images[i, :] for correlation calculation\n",
        "    c_vectors[i, :] = calculate_material_matrix(img, n=n, E_1=1., contrast_ratio=contrast_ratio, nu=0.3).flatten()\n",
        "\n",
        "\n",
        "delta_t = time.process_time() - start\n",
        "print(\"Elapsed time\", delta_t)\n",
        "\n",
        "name_str = 'n=%d_x=%d' % (n, x)\n",
        "\n",
        "name_str = name_str + \"_cr=\" + \"{:.4f}\".format(contrast_ratio)\n",
        "\n",
        "if single_volume_frac:\n",
        "  name_str = name_str + ('_vol_frac%.2f' % vol_frac_value)\n",
        "else:\n",
        "  name_str = name_str + '_all_vol_fracs'\n",
        "\n",
        "if single_a_r:\n",
        "  name_str = name_str + ('_ar%.2f' % a_r_value)\n",
        "else:\n",
        "  name_str = name_str + '_all_ar'\n",
        "\n",
        "if binary:\n",
        "  name_str = name_str + '_binary'\n",
        "\n",
        "name_str = name_str + '.h5'\n",
        "\n",
        "\n",
        "hf = h5py.File(name_str, 'w')\n",
        "\n",
        "hf.create_dataset('volume_fractions', data=volume_fractions)\n",
        "hf.create_dataset('areas_ellipse', data=areas_ellipse)\n",
        "hf.create_dataset('aspect_ratios', data=aspect_ratios)\n",
        "hf.create_dataset('contrast_ratio', data=contrast_ratio)\n",
        "hf.create_dataset('images', data=images)\n",
        "hf.create_dataset('c_vectors', data=c_vectors)\n",
        "hf.close()\n",
        "\n",
        "# Print some information\n",
        "print('Generated Data Set:')\n",
        "print('Mean volume fraction: ', np.mean(volume_fractions), ', should be 0.5')\n",
        "print('Mean ellipse area: ', np.mean(areas_ellipse), ', should be 0.5')\n",
        "print('Mean aspect ratio: ', np.mean(aspect_ratios), ', should be', np.mean(a_r))\n",
        "\n",
        "# plot some\n",
        "number_of_images = x\n",
        "rands = np.random.randint(0, number_of_images, 25)\n",
        "training_data = images[rands, :]\n",
        "training_targets = c_vectors[rands, 1]\n",
        "vmin = np.min(training_data.flatten())\n",
        "vmax = np.max(training_data.flatten())\n",
        "v = max(np.abs(vmin), np.abs(vmax))\n",
        "\n",
        "\n",
        "for i in range(25):\n",
        "    plt.subplot(5, 10, 2 * i + 1)\n",
        "    continuous_image_i = training_data[i, :].reshape(n, n)\n",
        "    discrete_image_i = np.zeros((n, n))\n",
        "    discrete_image_i[continuous_image_i > 0] = 1\n",
        "    plt.imshow(continuous_image_i, vmin=-v, vmax=v)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.colorbar()\n",
        "    plt.subplot(5, 10, 2 * (i + 1))\n",
        "    plt.imshow(discrete_image_i)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.title(\n",
        "        'A=%.2f, a_r=%.2f, Vol=%.2f' % (areas_ellipse[rands[i]], aspect_ratios[rands[i]], volume_fractions[rands[i]]))\n",
        "\n",
        "# print(\"Total time:\", time.process_time() - start)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example image saving"
      ],
      "metadata": {
        "id": "uK7g4SEG6HkD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(0)\n",
        "\n",
        "vmin = np.min(random.flatten())\n",
        "vmax = np.max(random.flatten())\n",
        "v = max(np.abs(vmin), np.abs(vmax))\n",
        "\n",
        "plt.imshow(random.reshape((32,32)), vmin=-v, vmax=v)\n",
        "#plt.imshow(img.reshape((32,32)))\n",
        "plt.axis('off')\n",
        "plt.colorbar()\n",
        "plt.savefig(\"./example_random\", bbox_inches='tight', pad_inches=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "sivYEpeWlFSc",
        "outputId": "931c87ec-6cf9-469a-8eb1-cfeac2d6531d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAARkAAADnCAYAAAAq/yLKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAT6ElEQVR4nO3dX4hk6VnH8ec59ad7/mxcwgSi2ZVEFHERRRnihReiBrKKEBQEcyGIInghKAii7I1eC7lRbwYM3gT1QpcIBtcNCEEw6kZCyGZ1Dd64EpDZdWZ2pme6qs55vOghadzz/LrqrXq76y2+H2jY7nfOOW9XVb97zvmd5309IgwAaumuugMADhuDDICqGGQAVMUgA6AqBhkAVU1V4w//6qfy6EkMT91y/OfX7vbpNtffepi2+cPHadvw7I207d3vujn68/sfyTt/8rzo43fkfXz/jZO07fFylrY9fHw0+vPJZCg61tF0lba99c6zadvw5vhr9W1vppvY8b38tYqJ58ea5PucnYz/3rP7yYfKzKYPF/kOh/x1XL7/etr29gvHadu9Hxzvyweeu5du83iRfwZe/8Tv5y/WGj7+4zfi7Xfy9+K8L33l9JWIeHGb421KDjIA9t/b7/T2z69851r/dvLt/3Grcnfeg0EGaFyY2WD5GdtVY5ABGhcWtoz1LpeuAoMMcAA4kwFQTVhYv8flQQwywAEYrNFBZpKnhhYiwvbk8tDFaKsiT5/l3RzmeR7aJ6nhIH7rmJa9Wcshf0GeLPMDrpYizy04lq3yYy3FseZPxl//2Ul+rT97V0TYUxFhi7ZuMX7a3y3EPYfVflwqdJ5/dqZdvT6GmfWtDjIA2tDsmQyA/RdmtuSeDIBawoLLJQAVhVm/v2MMgwzQurMnfvcXgwzQPLfetqqxrEoOMt1SRM4qws6GVXFKF5N8hzEXEfaRiLDn4y985AWxZl3eSRcR5WKV92OxyPvfLzefbeNUROIL0cf+cb7dJCl0nz3K/x+pqp9jmv9e6rEDT+JoX+b98F7E2536oOZNu54ERX12tnV247fRQQbA/jt7ToZBBkBFA2cyAGrhTAZAVWFu/R7PpMsgAxyAZi+XJjJdEr9U9ohzhXRpdSzSpfHpc62fi47MRIohEoJVn/dDFUHG6XibmoLoiZgvNsSHzU/yfswejf9us0f5nMGTd5/k/Zjkx+quqXhvnC/FK9KLp0REuqQ+wyV/s+oPvW665LaIzQttLwtnMkDjzh7G43IJQEXc+AVQTYRbr56OvWIMMsABGDiTAVDL2Y3f/f1T3t+eAVhL0zd+u5WIsAvOzlSKp+b47UUc2h+rQrzxfQ4zsfruVETYaYtZL+bdHRaiIHAxvp2a6Ox0IiLsVd6P6cO8bZaswDsRRZBq+WCfiti+YK5nX+ZRulqKVlGfOflmJx/+fri6S5a+1edkAOw/nvgFUN1AugSglrMCSQYZAJWEuS33uKxgf4c/AGuJMOujW+vrIu7+vLv/vbt/zd1fd/ff2LZ/nMkAzfNdPoy3MrPfioh/dfdnzOxL7v5qRHytdIdykHGRGroqqc5+X5XLijhxEPPF9kci+k6qsENF2BPRpub47cX/JZKY2sysO01idlHVrQJbF3MGzx7kr9X84XiVc6cqrU9O8o5M84+Wu/iDyJYkFjG1D/n7MohjySrsgnP8QTzGUHuO312VFUTEN8zsG0//+113f8PMPmRmdQYZAG3Y4MbvLXd/7dz3dyLiztg/dPcPm9kPmdk/bdM3BhmgcWG+yaRVdyPi9kX/yN1vmtlfmtlvRsSDbfrHIAM07mxJlN39Kbv7zM4GmM9ExF9tuz8GGaB5u1vczc9umP2Jmb0REZ/axT6JsIHGhZ098bvO1xp+1Mx+0cx+wt2//PTrp7fpH2cywAHY1ZlMRPyD6fLQjekIuxdLtqqK6qSLan+DmEi8P8rbViLCHpJiZR1hl00kPogKXF/lbd0iqzpON5Hx9uSJiKnF7bv5g/HnFfwkj7CHR3mE7fN5frCZmEg8iZVVTC2JRyPkQ7KyCnv8x6oSuubzuBFO7RKAes5u/O5vWQGDDNA85vgFUNHZjV8mrQJQEVM9AKhmwyd+Lx2DDHAAmp1IXMWGMt7OYkgVe4vXSEXYWaW1mdmQpKghKq0nIsJWBlGFXRRhq9cqn9vbpo/yYx3dz3+32YPxncbjfLLwYZHn7PIjv8y3SycgV9XUah11UcE/zAqrsLMIW3wGoqtYhR1mS1EBftU4kwEad3a5xCADoCLWwgZQDRE2gMq4XAJQ2Q7n+N05nS6paXxVCFNQzBZTVehY2DZN+iHSpdK5WEOcrqq5krskKerGp9w9258oxpzfz/t/dC9/07oH4ylSPM4LJG3IOxliEiVZ7JjNA63mBS5MngZVPClODLLXf7XK64e66ukStUsAKuFhPADVNXu5BGD/kS4BqI50CUA1EW4rBhkANbV7uaQKJFVbEkOGjCFF1Ch6mc3jaybmcK0QU4eI9LteFEgmKfBEJMeTUxFTqwj7f/PKSn80HmEPS5G/C3Ip2rId5m1ZUaWZxUws9ysem5D3UZP3WhZIls5RvAbuyQCojkEGQDU8JwOgOp6TAVBNhNmKSasA1MTlEoBq2r4nk8zVa2bmIrP1VVZJm8d44SJqrLHUaLY/8WapZUhDLVOrqtmThFjF1LOH+f6O7uWV0ZP7eS6ezuWr3uep+PiIpWjTeXzNzLrx035VTZ1tY2Y2zMoejVB/s1kV9rC8mjl+zfTn9qrt74UcgLUN5mt9XcTdP+3u/+PuX91V3xhkgMZFnN2TWedrDX9qZi/usn/ckwGa59bvKF2KiC+4+4d3srOnGGSAA7DBPZlb7v7aue/vRMSdCl36JgYZoHEb1i7djYjbFbvzHgwyQOsinxp5H5QPMmqZ2j6JPUUkrqipMoqm0RBx8yDbVJWt+N1EhXY2IXuXr+Rqs5PNl5s1M+vu59n3oCYMT/hRvkawHx/nG87zeDuyeLtCpXVpFbYnTwnoCDvf3y7sc1kB6RLQuHh643edr4u4+5+Z2T+a2fe6+1vu/ivb9o/LJeAA7OpyKSI+uZs9fQuDDHAA9vmJXwYZoHERDDIAKmu3QBJAE5qNsKMwcvbV5hG2XB+5dJDOkl4xsXcv1jOWc2OXVmEnbZ2Yv3v6OI+wJw9O07Z4+ChvW4xH36rS2q9fF215hB1H87TNZuPHU5PQywhbVGGrCn5ZhZ19flZqAe2aE4m7fLziqnEmAxyAPT6RYZABmseNXwDV7fGpDIMMcAA4kwFQTZiuubtqDDJA68J0HHbFdIStYjw5OXYSsYoY0kVVt7zeVP1IqmV9JSpzVbwt1utWEXaJrO9mZpPTPMLuTvJq6iGbLNzytZq7Y1FpfTOPsENF2CJyTqNq9dKrmFpUWstJ6IWsct6X6g+m7iDQ7HMyABrBIAOgHufGL4DKOJMBUE1cMDPjFWOQAQ5Cq4OM6re6nZ2kS2p3nZozuGCOXDOzLkmRVAowLETkIAskRZuQXUq7eH27LL0zMzvN5/gdTvPiSZ+M/95+7Vq+v2fytv5GnkrJuZ5VoWy2yTx/z/q5eK9L06UstZTpUtmx1sblEoCqGGQAVNPyw3gA2sDDeADqIl0CUFPFife2xiADtC6s4Ru/MsIWmy3FBLXpNqLoTy6JK4ouk250CxFrqqVGJ6qIUxTiqdcxaVNz2qolgmMh1rdVF+5JhG3X8kLH/pm8bXWj7P9fXfI5UHNAD/P8PVNL0cakcA7rJMLOHpk4O1jRodbk3PgFUFmzZzIA2lD4MOhlYJABWrfnz8ns72ItANbmsd7XWvtyf9Hd/93dv+7uv7Nt3xhkgEMQa35dwN0nZvbHZvZTZvaCmX3S3V/YpmsMMgDO+6iZfT0i/jMiFmb252b2iW12eMEcv2rpVTEs9uMZn/ciphaVxWrJ1pK2TqS8qpI2Jmqi2bxJyeaZjUse/ruj8arp4WYeUy/eN0vbVjfyX0DPXzz++ncrEWHPxCMJ6hNeeBsje2zCRR9r2+BhvFvu/tq57+9ExJ1z33/IzP7r3PdvmdmPbNM3bvwCrQvbpKzgbkTcrtib92CQAQ7B7k6i/tvMnj/3/XNPf1aMezLAAdhhuvQvZvY97v4Rd5+b2S+Y2V9v0zfOZIBDsKMzmYhYufuvm9krZjYxs09HxOvb7JNBBjgEO7znHBGfM7PP7Wp/DDJA4zZ50O4qlFdhi6pYXyUZZfZzM/Nl3qbiS9mWxNHZz8/6ISJsEZW6uruvinOTu2JyCVVVPawm6e7ETpMIu7+ZTwi+eF++v9W1vB/dUpXwj78gsSiLsFWltXpMQC7DnFZh59tUf+yfSasA1NTumQyANjDIAKim6XsyANrAIAOgJrWS6lXjiV8AVRWfyaiJnS2rtl7lGZ+fighbxJeqorqkClvF26Emilb/JymIsFX18DAVFc7TfMPuOI+j/fp4tfXqZl5pvbyR/2Iqwp7kS3Kn/0dWqb2KqdXrKFPlggjbxeej+j0TLpcAVMONXwDVMcgAqIpBBkAtbvudLjHIAK1r+p6M6ria43cYH1ZDpUtiaVtdIJl3I1umVo36av5ZU0viqhVsxS6z9EMV/fViWVab52mQJ0WQZmaRJE/LG3kRpEqX+mtpk5mYOzpL/uTrK14OOVeyqmktSAtlgWRtzQ4yANrAIAOgpnYvlwC0gUEGQDVBugSgNs5kANTU7D0ZuRStkkTYaeGkWbq0rZlZt8y3817MNZxspubjLY63C6dYzebyHfIk2oYjUcR5PE/bXBRI9tfH21Sh4+p62mR9fihZTJoVT/alcyiruZIVVSC5j5cmrQ4yABoQxiADoB63hi+XALSBQQZAXQwyAKpikAFQzcFWYe84xnMRb6uYuhOxcho1FsaTpZXWOmId33KYl1VhDyLCnlwbn8fXzGy4Pp6Zr45FP/LdWX+kKufFPpPqcxeV+CVzKF+0nZQ9GlG4u524hEHG3X/ezH7PzL7PzD4aEa+tsx2rFQAHwIf1vrb0VTP7OTP7wiYbcbkEHIDLuFyKiDfMzFzMBzSGQQZo3WYP491y9/OXOXci4s7O+3QOgwxwCNYfZO5GxO2s0d0/b2YfHGl6KSI+W9AzBhmgdbt84jciPrabPX0LgwxwAOSKrldMV2GX3o3udhtalVRaV6Gqt7vCiDWbSFy8MytRhT1cyzf0ZZ4598fj5co6ws5/52Eu2k5FFXnS/eznF4muLFguOTOIq6rOvqQCSXf/WTP7QzP7gJn9jbt/OSI+ftF2nMkAB+CS0qWXzezlTbdjkAEOwf5eLTHIAIeg3bICAG1gkAFQDasVAKip6ZnxirP3LMKeluaQhf3I0ssa5bKqQlsdL3mphryYWk7S3R/nr7GakL0/Hu/III4lY+pZYdt0/MUaxITg8g/sEt/rq63C3t9RhjMZ4AA0eyYDoAGsVgCgNm78AqiKQQZAPWHt3vhVhYly4s7peBTgyc/NzGKy+5lAs/ld1dKlck7YUuKuXHY8tUxtLwoks5TIzKxb5L94f5SkS2q5XJEShWoTn7r0PVOFjuIPTCV7MvVTSrarPAZw4xdAXQwyAGpp+mE8AA2IaHfSKgCN2N8xhkEGOARcLgGoJ8ys1cslGWELMRvfrassP9nmbEMxJ6xcAnbzYrs6EbY4XtIXNcevLJ4sjbCT5WFVP1RMbcnyu2YXvMZZm9gmxIeg9P0sibev9Gxif8cYzmSAQ8DlEoCqSJcA1EMVNoCazh7G299RhkEGOARUYQOoqdkzGV+J4VHFyvOkdFdUWsc870ok876a6Ygyi6pLqoDNrPgWvo7Zx/ep+tjPRRW2aJvM818ui6pVhG1qad6pirBV23j/1Wso02bVWNqWkH3sN9/f+gc27skAqInaJQC17fHlUo3nWwFcpqeLu63ztQ13/wN3/zd3/4q7v+zuz66zHYMMcAgi1vvazqtm9v0R8QNm9qaZ/e46GzHIAIcg1vza5hARfxcRq6ffftHMnltnO+7JAAfAh7WvhW65+2vnvr8TEXcKDvnLZvYX6/zDSlXY49lx9vOzNhGvijY5KXgay4oIVexPxpqlS6VmE4mrKmwVbyfV1GZmg4i3s+Vh5eshKq19kn/o1WMCaQxcY0JwpeB4V1akGLbJw3h3I+J21ujunzezD440vRQRn336b14ys5WZfWadA3ImAzTOLXb2MF5EfEwey/2XzOxnzOwnI9Y7KIMMcAguIcJ29xfN7LfN7Mci4mTd7RhkgENwOc/J/JGZHZnZq372xP8XI+LXLtqIQQZo3Wb3ZMoPE/HdJdsxyAAHYIN06dIxyADN28mDdtXIQaZblpWOxlESYasqbFFpPahYVm2X/HayClvEskppfBnJhq5iXhEry+g7mVhd7VNVTOsIu3Ad9USNdatL18lO1+sW3ZhUr8JudJAB0Ij9vVpikAEOQbOTVgFoBIMMgGoizPr9vV5ikAEOAWcyAKpqdZBRE4mriuohibB7VU09zdt6NQG2qsLOYllVWazi1RpnpFlUWhhh63i+YEJ20Q8VU7uIvgcVixdUYavsuEr0nbwm6jGGKpXi39y5mTHHL4B6wiy4JwOgljBu/AKorNV7MgAawSADoJ6GCyRNLVMr0qUsReqviURKFEGqeWt1mpL9vGwJVS+uqFOxQ94kOpLvTqVScgnezbdRCVLX5Z+doWSOX6VCciP7kRVIls7zvK0wM6Z6AFBVs2cyABpAWQGAmsIseE4GQFU88QugKu7JAKgmot10yft8YtLBZ3lbUtC4vC4KHQsL+9QcvzsvkFzlTa7eYxFf+rDbbLM4ZS8oTNQRdtljArsukFTK52XOdli2v53gTAZAPWEhTgiuGoMM0DqmegBQHRE2gFrCzIIzGQDVBJNWAahsn2/8euxx9AXgYu7+t2Z2a81/fjciXqzZn/+PQQZAVQVLnwPA+hhkAFTFIAOgKgYZAFUxyACo6v8AiNBU4Ie8wc8AAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "jOJXoxnI6UYl",
        "jjTtAHjK6QUR",
        "uK7g4SEG6HkD"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}